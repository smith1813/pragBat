---
title: "Prag Bat Summary"
output:
  html_document:
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, warning = F, message = F)

library(tidyverse)
library(knitr)
library(ggthemes)
library(jsonlite)
library(readxl)
library(corrr)
library(corrplot)
library(ggcorrplot)
library(reshape2)
#library(psych)
library(readODS)
#library(brms)
library(psy)
library(tidyboot)
library(lubridate)
library(ggpubr)
library(lavaan)
library(blavaan)
library(semPlot)
```

```{r, include=FALSE}
data <- bind_rows(
  read_csv("../data/data_r1.csv") %>%filter(task != "training") %>%mutate(round = "R1"),
  read_csv("../data/data_r2.csv") %>%mutate(round = "R2")
  ) %>%
  mutate(round = factor(round),
         id = paste(round, id, sep = "_"))
  
```

```{r, include=FALSE}
data %>%
  group_by(subage) %>%
  summarise(n= length(unique(id)))
```
# Objective

Assess reliability of and relations between different pragmatic inference tasks which we have developed over the years.

# Sample size

Our goal was to test at least 20 children per age group and round twice. Children were tested in a kindergarten in Leipzig.

```{r}
data %>%
  group_by(subage,id,round) %>%
  summarise(testdays = length(unique(test_day))) %>%
  group_by(round,subage) %>%
  summarise(n = length(unique(id)),
            complete_retest_data = sum(testdays == 2)) %>%
  kable()
```

# Results by Task

All tasks had 5 trials, except for card sorting, which had 6. All subjects got the tasks in the same order and the same version of each task.

Round 1 included the following tasks: 

* Informativeness (same setup and stimuli as in MCC)
* Preference (as in MCC)
* Novelty (as in SPIN)
* Mutual exclusivity (as in SPIN, with fewer items)
* Card sorting (DCCS sensu Zelazo, 2006)

Round 2 included the following tasks: 

* Simple informativeness (same setup and stimuli as in Frank & Goodman, 2014)
* Ad-hoc implicature (same stimuli as Yoon & Frank, 2019)
* Discourse continuity (as in DISCON)
* Mutual exclusivity (as in SPIN, with fewer items, same as R1)
* Card sorting (DCCS sensu Zelazo, 2006, same as R1)

For mutual exclusivity and card sorting we have a direct replication. The plot below shows all data, including data from children who were tested only once.

```{r}
p1 <- data %>%
  group_by(round, id,age, subage,task) %>%
  filter(task != "training") %>%
  summarise(mean = mean(correct))

p2 <- p1 %>%
  group_by(round,subage,task) %>%
  tidyboot_mean(column = mean) %>%
  mutate(chance = ifelse(task == "discourse_continuity", 1/3, 1/2))

ggplot()+
  geom_hline(data = p2, aes(yintercept = chance), lty = 2)+
  geom_smooth(data = p1, aes(x = age, y = mean, lty = round), method = "lm", col = "black", size = 1)+
  geom_jitter(data = p1, aes(x = age, y = mean, pch = round), alpha = .5, width = .05, height = .01)+
  geom_pointrange(data = p2, aes(x = as.numeric(as.character(subage))+.5, y = mean, ymin = ci_lower, ymax = ci_upper, col = factor(subage), pch = round), position = position_dodge(width = .5))+
  facet_wrap(~task)+
  labs(x = "Age Group", y = "Proportion Correct") +
  scale_color_ptol(name = "Age") +
  ylim(-0.05, 1.05)+
  theme_few()+
  theme(legend.position = c(.85,.1), legend.direction = "horizontal")

```

# Reliability

Based on simple Pearson correlations on the data aggregated by subject, task and test day.

```{r}
wide_data <- data %>%
  filter(task != "training") %>%
  droplevels() %>%
  group_by(round,id,task, test_day) %>%
  summarise(mean = mean(correct)) %>%
  spread(test_day, mean) %>%
  na.omit() %>%
  rename("Day1" = `1`,
         "Day2" = `2`) 

reli <- wide_data %>%
  group_by(round, task) %>%
  summarize(reli = cor.test(Day1,Day2)$estimate,
            lci = cor.test(Day1,Day2)$conf.int[1],
            uci = cor.test(Day1,Day2)$conf.int[2],
            p = cor.test(Day1,Day2)$p.value, 
            n = n()) %>%
  mutate_if(is.numeric, round, digits = 2)

reli %>%
  kable()
```
Explore consolidating across rounds. 

```{r}
reli_task <- wide_data %>%
  group_by(task) %>%
  summarize(reli = cor.test(Day1,Day2)$estimate,
            lci = cor.test(Day1,Day2)$conf.int[1],
            uci = cor.test(Day1,Day2)$conf.int[2],
            p = cor.test(Day1,Day2)$p.value, 
            n = n()) %>%
  mutate_if(is.numeric, round, digits = 2)

reli_task %>%
  arrange(desc(reli)) %>%
  kable()
```

# Correlations between tasks

Based on simple Pearson correlations on the data aggregated by subject and task.

```{r, fig.align="center"}
cor_r1 <- data %>%
  filter(round == "R1") %>%
  droplevels() %>%
  group_by(id,task) %>%
  summarise(mean = mean(correct)) %>%
  spread(task, mean) %>%
  ungroup() %>%
  select(-id) %>%
  corrr::correlate(diagonal = reli %>%
                     filter(round == "R1") %>%
                     pull(reli)) %>%
  gather(task, cor, -rowname) %>%
  mutate(cor = replace(cor, duplicated(cor), NA)) %>%
  mutate_if(is.numeric, round, digits = 2) %>%
  na.omit() %>%
  mutate(round = "R1")

cor_r2 <- data%>%
  filter(round == "R2") %>%
  droplevels() %>%
  group_by(id,task) %>%
  summarise(mean = mean(correct)) %>%
  spread(task, mean) %>%
  ungroup() %>%
  select(-id) %>%
  corrr::correlate(diagonal = reli%>%filter(round == "R2") %>%pull(reli)) %>%
  gather(task, cor, -rowname) %>%
  mutate(cor = replace(cor, duplicated(cor), NA)) %>%
  mutate_if(is.numeric, round, digits = 2) %>%
  na.omit() %>%
  mutate(round = "R2")
  
cor <- bind_rows(
  cor_r1,
  cor_r2
)

ggarrange(
ggplot(cor_r1, aes(x = rowname, y = task, fill = cor))+
  geom_tile(color = "white")+
  labs(x = "", y = "")+
  scale_fill_gradient2(low = "#CC6677", high = "#117733", mid = "white", 
   midpoint = 0, limit = c(-1,1), space = "Lab", 
   name="Correlation") +
   coord_fixed()+
  theme_few()+
  geom_text(aes(label = cor), color = "black", size = 3) +
  ggtitle("Round 1")+
  theme(
        legend.position = "right",
        legend.direction = "horizontal",
        axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)),


ggplot(cor_r2, aes(x = rowname, y = task, fill = cor))+
  geom_tile(color = "white")+
  labs(x = "", y = "")+
  scale_fill_gradient2(low = "#CC6677", high = "#117733", mid = "white", 
   midpoint = 0, limit = c(-1,1), space = "Lab", 
   name="Correlation") +
   coord_fixed()+
  theme_few()+
  geom_text(aes(label = cor), color = "black", size = 3) +
  ggtitle("Round 2")+
  theme(
        legend.position = "right",
        legend.direction = "horizontal",
        axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)),
common.legend = T, legend = "top"

)
```

# Factor analysis

## EFA

Average across task days. 

```{r}
efa_data <- filter(data, round == "R1") %>%
  group_by(id, task) %>% 
  summarise(correct = mean(correct)) %>%
  pivot_wider(names_from = task, values_from = correct)
```

```{r}
fa_data <- as.matrix(dplyr::select(ungroup(efa_data), -1))
f1 <- factanal(fa_data, 1)
f1
```


```{r}
f2 <- factanal(fa_data, 2)
f2
```
`


## CFA
[https://lavaan.ugent.be/tutorial/cfa.html]()

Data

```{r}
lavaan_data_1 <- filter(data, round == "R1") %>%
  group_by(id, task) %>%
  summarise(correct = mean(correct)) %>%
  pivot_wider(names_from = task, values_from = correct)

lavaan_data_2 <- filter(data, round == "R2") %>%
  group_by(id, task) %>%
  summarise(correct = mean(correct)) %>%
  pivot_wider(names_from = task, values_from = correct)

lavaan_data_r1 <- filter(data, round == "R1") %>%
  group_by(test_day,id, task) %>%
  summarise(correct = mean(correct)) %>%
  pivot_wider(names_from = c(task,test_day), values_from = correct)%>%
  na.omit()

lavaan_data_r2 <- filter(data, round == "R2") %>%
  group_by(test_day, id, task) %>%
  summarise(correct = mean(correct)) %>%
  pivot_wider(names_from = c(task,test_day), values_from = correct)%>%
  na.omit()
```
### Reliability

```{r}
model_rel_1 <- '
pragmatic_1  =~ informativeness_1  + mutual_exclusivity_1 + novelty_1 + preference_1
pragmatic_2  =~ informativeness_2  + mutual_exclusivity_2 + novelty_2 + preference_2

pragmatic_1 ~~ pragmatic_2

informativeness_1 ~~ informativeness_2
mutual_exclusivity_1 ~~ mutual_exclusivity_2
novelty_1 ~~ novelty_2
preference_1 ~~ preference_2
'

fit_rel_1 <- cfa(model_rel_1, data=lavaan_data_r1, std.lv = TRUE)

summary(fit_rel_1,  ci = T)

```

```{r}
model_rel_2 <- '
pragmatic_1  =~ ad_hoc_implicature_1  + mutual_exclusivity_1 + simple_inf_1 + discourse_continuity_1
pragmatic_2  =~ ad_hoc_implicature_2  + mutual_exclusivity_2 + simple_inf_2 + discourse_continuity_2

pragmatic_1 ~~ pragmatic_2

ad_hoc_implicature_1 ~~ ad_hoc_implicature_2
mutual_exclusivity_1 ~~ mutual_exclusivity_2
simple_inf_1 ~~ simple_inf_2
discourse_continuity_1 ~~ discourse_continuity_2

'

fit_rel_2 <- cfa(model_rel_2, data=lavaan_data_r2, std.lv = TRUE)

summary(fit_rel_2, ci = T)

semPaths(fit_rel_2, "std")

fitmeasures(fit_rel_2)

```

### Relations between constructs

```{r}
model_1 <- '
pragmatic  =~ informativeness  + mutual_exclusivity + novelty + preference
ef  =~ card_sorting
'

fit_1 <- cfa(model_1, data=lavaan_data_1, std.lv = TRUE)

summary(fit_1, ci = T)

semPaths(fit_1, "std")

fitmeasures(fit_1)
```

```{r}
model_2 <- '
pragmatic  =~ ad_hoc_implicature  + mutual_exclusivity + simple_inf + discourse_continuity
ef  =~ card_sorting
'

fit_2 <- cfa(model_2, data=lavaan_data_2, std.lv = TRUE)

summary(fit_2, ci = T)

semPaths(fit_2, "std")

fitmeasures(fit_2)
```



### Bayesian estimation

#### Reliability
```{r}
bfit_rel_1<- bcfa(model_rel_1, 
                   data=lavaan_data_r1, 
                   std.lv = TRUE,
                   n.chains = 4,
                   burnin = 2000,
                   sample = 4000)

summary(bfit_rel_1, ci = T)
```

```{r}

bfit_rel_2 <- bcfa(model_rel_2, 
                   data=lavaan_data_r2, 
                   std.lv = TRUE,
                   n.chains = 4,
                   burnin = 2000,
                   sample = 4000)

summary(bfit_rel_2, ci = T)

semPaths(bfit_rel_2, "std")
```

#### Relations between constructs

```{r}
bfit_1 <- bcfa(model_1, 
                   data=lavaan_data_1, 
                   std.lv = TRUE,
                   n.chains = 4,
                   burnin = 2000,
                   sample = 4000)

summary(bfit_1, ci = T)



```

```{r}
bfit_2 <- bcfa(model_2, 
                   data=lavaan_data_2, 
                   std.lv = TRUE,
                   n.chains = 4,
                   burnin = 2000,
                   sample = 4000
               )

summary(bfit_2, ci = T)

semPaths(bfit_2, "std")
```

